{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from transformers import WhisperFeatureExtractor, WhisperTokenizer, WhisperProcessor\n",
    "from datasets import load_dataset\n",
    "import soundfile as sf\n",
    "from IPython.display import Audio\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from dask import delayed\n",
    "from datasets import load_from_disk\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aws_access_key_id=\"ASIA4PPDI6ALBMFZ7QEW\"\n",
    "# aws_secret_access_key=\"MxwKUrMU5wiyIMS2WfdEmN+K2jz9gOeUlJGBOCf7\"\n",
    "# aws_session_token=\"IQoJb3JpZ2luX2VjEAYaCWV1LXdlc3QtMyJHMEUCIAmkFWTZDG8ZziDIqx/3jrxvy6YBez8Ln9pCa7b+mQLpAiEAo9leNjgIoOP0Ped/O8+rby/Y47bdhfPAcuRqCaXbE6Uq9gIIXxAAGgw4NTc4NTk0ODU3MTgiDAfgSRDN4STMsCBucCrTAocIFVAw0YF8cwXDF34c61nBtXTexi9/D/Tm6AZcOZg+JiyTUm72kNyx1zUV38t2RC6WgX3hAm/j6Ce9BCmvwPe/uQrqznbUd4bVZfWc/OR6cTK7BePe0hb+hfrIbMJzhjODbqaAXDwk9E/waejcJukuV7XbZ1bZok6fQGpPc/wLrkXA4ookADrl1wB93O6INojIoFQDLN2s694/zX/j+9zPCyM/ycL+tnIhXGiUjoxOD3l47yYF4J1dqTVFO7N2dCGctXncRt9ojbElKwL8T1i8XhMlfMnItCDneK4fzVULj8Ldl88dB4+Wd2XdDYbsrbV1YI6nQ89X8/CXLsK5Ff+zLs3ctWNYteu5i0wUTdv10AEK1Wsc1RBkV9K7mi5NNyftKsazcQLJeYxns7pVHyKSKA0DV7JobdcqCgDGJUfuI9Yj1nE7seXOuhUt2MO+Tmby/DDgl5q4BjqnATu1Eikl/+wdO/JaxI1jKM77+UQrV4KGlvBZKNh7voSkezjFUIF3eJmmDpFF22TGAeRCQcVSwTSZoooJkUKJIkikIeF9CmrF679LrjoS+HqIU4+iay/Nr9eeZUGRDNXLaTHmSkMjh7Ge+7L8Mv3JmLvRkP1RQ2WRAJIsIJHQWdxmd/0hASKB538WR9vYKycfTOjjAjYFnZOVATmtj1+MP8z1ogB8EjrF\"\n",
    "\n",
    "# import boto3\n",
    "\n",
    "# s3 = boto3.client('s3', aws_access_key_id=aws_access_key_id, aws_secret_access_key=aws_secret_access_key, aws_session_token=aws_session_token)\n",
    "# s3_bucket = 'sagemaker-eu-west-3-857859485718'\n",
    "# response = s3.list_objects(Bucket=s3_bucket)\n",
    "# response\n",
    "\n",
    "# import s3fs\n",
    "# train_path = f's3://{s3_bucket}/oussama/train/'\n",
    "# test_path = f's3://{s3_bucket}/oussama/test/'\n",
    "# s3 = s3fs.S3FileSystem(key=aws_access_key_id, secret=aws_secret_access_key)\n",
    "# Charger les datasets depuis S3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"/Users/oussamanaji/Library/CloudStorage/OneDrive-CentraleSupelec/Diago_TOUT/WhisperHF/Dataset\"\n",
    "train_dataset = load_from_disk(f\"{dataset_dir}/train\")\n",
    "test_dataset = load_from_disk(f\"{dataset_dir}/test\")\n",
    "common_voice = DatasetDict()\n",
    "common_voice[\"train\"] = train_dataset\n",
    "common_voice[\"test\"] = test_dataset\n",
    "\n",
    "COLUMNS_TO_KEEP = [\"transcript\", \"audio\"]\n",
    "all_columns = common_voice[\"train\"].column_names\n",
    "columns_to_remove = set(all_columns) - set(COLUMNS_TO_KEEP)\n",
    "common_voice = common_voice.remove_columns(columns_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['audio', 'transcript'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['audio', 'transcript'],\n",
       "        num_rows: 10\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_voice[\"train\"] = common_voice[\"train\"].select(range(100))\n",
    "common_voice['test'] = common_voice[\"test\"].select(range(10))\n",
    "common_voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"openai/whisper-small\"\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(model_id)\n",
    "tokenizer = WhisperTokenizer.from_pretrained(model_id, language=\"French\", task=\"transcribe\")\n",
    "processor = WhisperProcessor.from_pretrained(model_id, language=\"French\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 22.32 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 25.13 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def prepare_dataset(batch):\n",
    "    # load and resample audio data from 48 to 16kHz\n",
    "    audio = batch[\"audio\"]\n",
    "\n",
    "    # compute log-Mel input features from input audio array\n",
    "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "\n",
    "    # encode target text to label ids\n",
    "    batch[\"labels\"] = tokenizer(batch[\"transcript\"]).input_ids\n",
    "    return batch\n",
    "common_voice = common_voice.map(prepare_dataset, remove_columns=common_voice.column_names[\"train\"], num_proc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperForConditionalGeneration\n",
    "model = WhisperForConditionalGeneration.from_pretrained(model_id)\n",
    "model.generation_config.language = \"French\"\n",
    "model.generation_config.task = \"transcribe\"\n",
    "model.generation_config.forced_decoder_ids = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "import evaluate\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "    decoder_start_token_id: int\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
    "        # first treat the audio inputs by simply returning torch tensors\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # get the tokenized label sequences\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # pad the labels to max length\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        # if bos token is appended in previous tokenization step,\n",
    "        # cut bos token here as it's append later anyways\n",
    "        if (labels[:, 0] == self.decoder_start_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(\n",
    "    processor=processor,\n",
    "    decoder_start_token_id=model.config.decoder_start_token_id,\n",
    ")\n",
    "\n",
    "\n",
    "metric = evaluate.load(\"wer\")\n",
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    # replace -100 with the pad_token_id\n",
    "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "output_dir = \"/Users/oussamanaji/Library/CloudStorage/OneDrive-CentraleSupelec/Diago_TOUT/WhisperHF\"\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=output_dir,  # change to a repo name of your choice\n",
    "    per_device_train_batch_size=1,  # ou 2 si n√©cessaire\n",
    "    per_device_eval_batch_size=1,  # ou 2 si n√©cessaire\n",
    "    gradient_accumulation_steps=1,  # increase by 2x for every 2x decrease in batch size\n",
    "    learning_rate=1e-5,\n",
    "    #warmup_steps=500,\n",
    "    max_steps=500,\n",
    "    gradient_checkpointing=False,\n",
    "    fp16=False,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=128,\n",
    "    save_steps=50,\n",
    "    eval_steps=50,\n",
    "    logging_steps=10,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=common_voice[\"train\"],\n",
    "    eval_dataset=common_voice[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have passed task=transcribe, but also have set `forced_decoder_ids` to [[1, 50259], [2, 50359], [3, 50363]] which creates a conflict. `forced_decoder_ids` will be ignored in favor of task=transcribe.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:38<00:00,  3.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription r√©elle: pendant le second si√®cle je fis serment d'ouvrir tous les tr√©sors de la terre √† quiconque me mettrait en libert√© mais je ne fus pas plus heureux dans le troisi√®me je promis de faire puissant monarque mon lib√©rateur d'√™tre toujours pr√®s de lui en esprit\n",
      "Transcription mod√®le :  Pendant le second si√®cle, je fis serment d'ouvrir tous les tr√©sors de la terre, √† qui compte-me mettre en libert√©. Mais je ne fus pas plus heureux. Dans le troisi√®me, je promis de faire puissant mon arc, mon lib√©rateur, d'√™tre toujours pr√®s de lui en esprit.\n",
      "--------------------------------------------------\n",
      "Transcription r√©elle: non ta mort est certaine dit le g√©nie choisis seulement de quelle sorte tu veux que je te fasse mourir le p√™cheur le voyant dans la r√©solution de le tuer en eut une douleur extr√™me non pas tant pour l'amour de lui qu'√† cause de ses trois enfants dont il plaignait la mis√®re o√π ils allaient √™tre r√©duits par sa mort\n",
      "Transcription mod√®le :  ‚Äî Non, ta mort est certaine, dit le g√©nie. Choisis seulement de quelle sorte tu veux que je te fasse mourir. Le p√™cheur, le voyant dans les r√©solutions de le tuer, enut une douleur extr√™me, non pas tant pour l'amour de lui qu'√† cause de ces trois enfants dont il cl√©nait la mis√®re o√π ils allaient √™tre r√©duits par sa mort.\n",
      "--------------------------------------------------\n",
      "Transcription r√©elle: la nuit suivante appela sa soeur quand il en fut temps si vous ne dormez pas ma soeur lui dit-elle je vous prie en attendant le jour qui para√Ætra bient√¥t de continuer le conte du p√™cheur\n",
      "Transcription mod√®le :  D√©narza, de la nuit suivante, a place √† s≈ìur quand il en fut temps. ¬´ Si vous ne dormez pas √† ma s≈ìur, lui dit-elle, je vous prie, en attendant le jour qui para√Ætra bient√¥t, de continuer le compte du p√™cheur. ¬ª\n",
      "--------------------------------------------------\n",
      "Transcription r√©elle: √† l'aspect d'un monstre d'une grandeur si d√©mesur√©e le p√™cheur voulut prendre la fuite mais il se trouva si troubl√© et si effray√© qu'il ne put marcher salomon\n",
      "Transcription mod√®le :  √Ä l'aspect d'un monstre d'une grandeur si d√©mesur√©e, le p√™cheur voulu prendre la suite, mais il se trouva si troubl√© et si effray√© qu'il ne pu marcher. ¬´ Salomon !\n",
      "--------------------------------------------------\n",
      "Transcription r√©elle: le sultan qui n'avait pas moins d'envie que dinarzade d'entendre la fin de ce conte diff√©ra encore la mort de la sultane fin de la dixi√®me nuit cet enregistrement fait partie du domaine public\n",
      "Transcription mod√®le :  Le sultan qui n'avait pas moins d'envie que Dinarzad n'entend de la fin de ce compte diff√®re √† encore la mort de la sultan. Fin de la dixi√®me nuit. Cet enregistrement fait partie du domaine public.\n",
      "--------------------------------------------------\n",
      "Transcription r√©elle: s'√©cria d'abord le g√©nie salomon grand proph√®te de dieu pardon pardon jamais je ne m'opposerai √† vos volont√©s j'ob√©irai √† tous vos commandements scheherazade apercevant le jour interrompit l√† son conte\n",
      "Transcription mod√®le :  S'√©cria d'abord le g√©nie, Salomon, grand proph√®te de Dieu, pardon, pardon, jamais je ne me poserai vos volont√©s. Je baillerai √† tous vos commandements. Chez Erasadz, apercevant le jour, interrompila son compte.\n",
      "--------------------------------------------------\n",
      "Transcription r√©elle: seigneur vous savez que je ne jette mes filets que quatre fois chaque jour je les ai d√©j√† jet√©s trois fois sans avoir tir√© le moindre fruit de mon travail il ne m'en reste plus qu'une je vous supplie de me rendre la mer favorable comme vous l'avez rendue √† mo√Øse\n",
      "Transcription mod√®le :  Seigneur, vous savez que je ne jette mes filets que quatre fois chaque jour. J'ai d√©j√† jet√© trois fois sans avoir tir√© le moindre fruit de mon travail. Il ne m'en reste plus qu'une. Je vous supplie de me rendre le maire favorable, comme vous l'avez rendu √† Mo√Øse.\n",
      "--------------------------------------------------\n",
      "Transcription r√©elle: rien n'est plus surprenant que l'histoire du p√™cheur r√©pondit la sultane et vous en conviendrez la nuit prochaine si le sultan me fait la gr√¢ce de me laisser vivre schahriar curieux d'apprendre le succ√®s de la p√™che du p√™cheur ne voulut pas faire mourir ce jour-l√† scheherazade\n",
      "Transcription mod√®le :  Rien n'est plus surprenant que l'histoire du p√™cheur r√©pondit la sultan, et vous en conviendrez la nuit prochaine si le sultan me fait la gr√¢ce de me laisser vivre. Chariar, curieux d'apprendre le succ√®s de la p√™che du p√™cheur, ne voulu pas faire mourir ce jour-l√† chez Razad.\n",
      "--------------------------------------------------\n",
      "Transcription r√©elle: √† ce discours le g√©nie regardant le p√™cheur d'un air fier lui r√©pondit parle-moi plus civilement tu es bien hardi de m'appeler esprit superbe eh bien repartit le p√™cheur vous parlerai-je avec plus de civilit√© en vous appelant hibou du bonheur\n",
      "Transcription mod√®le :  √Ä ce discours, le g√©nie, regardant le p√™cheur de nerfi√®re, lui r√©pondit, ¬´ Parle-moi plus sililement, tu es bien hardi de m'appeler ¬´ Esprit Superbe ¬ª. ¬´ Et bien, repartis le p√™cheur, vous parlerez-je avec plus de civilit√© en vous appelant ¬´ Ibu du bonheur ¬ª ? ¬ª\n",
      "--------------------------------------------------\n",
      "Transcription r√©elle: lui fit penser qu'il devait √™tre rempli de quelque chose de pr√©cieux pour s'en √©claircir il prit son couteau et avec un peu de peine il l'ouvrit il en pencha aussit√¥t l'ouverture contre terre mais il n'en sortit rien ce qui le surprit extr√™mement\n",
      "Transcription mod√®le :  lui fit penser qu'il devait √™tre rempli de quelque chose de pr√©cieux. Pour s'en √©claircir, il prit son couteau, et avec un peu de peine, il l'ouvrit. Il en pencha aussit√¥t l'ouverture contre terre, mais il n'en sortit rien, ce qui le surprit extr√™mement.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Faire des pr√©dictions sur l'ensemble de test\n",
    "predictions = trainer.predict(common_voice[\"test\"])\n",
    "\n",
    "# Les ids des pr√©dictions et des √©tiquettes\n",
    "pred_ids = predictions.predictions\n",
    "label_ids = predictions.label_ids\n",
    "\n",
    "# label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
    "\n",
    "# D√©coder les pr√©dictions et les √©tiquettes\n",
    "pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "label_str = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "for i in range(10):  # Par exemple, afficher les 10 premi√®res\n",
    "    print(f\"Transcription r√©elle: {label_str[i]}\")\n",
    "    print(f\"Transcription mod√®le : {pred_str[i]}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 10/500 [00:18<16:36,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7014, 'grad_norm': 66834.4921875, 'learning_rate': 9.800000000000001e-06, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñç         | 20/500 [00:50<27:23,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.6648, 'grad_norm': 486.5415344238281, 'learning_rate': 9.600000000000001e-06, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|‚ñå         | 30/500 [01:21<23:33,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4579, 'grad_norm': 505.19488525390625, 'learning_rate': 9.4e-06, 'epoch': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|‚ñä         | 40/500 [01:49<19:20,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6163, 'grad_norm': 25.44746971130371, 'learning_rate': 9.200000000000002e-06, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 50/500 [02:12<16:37,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0226, 'grad_norm': 27.586471557617188, 'learning_rate': 9e-06, 'epoch': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 10%|‚ñà         | 50/500 [03:12<16:37,  2.22s/it]/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/modeling_utils.py:2618: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6243526935577393, 'eval_model_preparation_time': 0.0021, 'eval_wer': 49.52153110047847, 'eval_runtime': 60.2274, 'eval_samples_per_second': 0.166, 'eval_steps_per_second': 0.166, 'epoch': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|‚ñà‚ñè        | 60/500 [04:14<49:32,  6.76s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4428, 'grad_norm': 31.742855072021484, 'learning_rate': 8.8e-06, 'epoch': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|‚ñà‚ñç        | 70/500 [04:37<16:46,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5696, 'grad_norm': 12.226349830627441, 'learning_rate': 8.6e-06, 'epoch': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|‚ñà‚ñå        | 80/500 [04:57<13:44,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7865, 'grad_norm': 27.385589599609375, 'learning_rate': 8.400000000000001e-06, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|‚ñà‚ñä        | 90/500 [05:16<12:25,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7523, 'grad_norm': 15.013405799865723, 'learning_rate': 8.2e-06, 'epoch': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 100/500 [05:34<12:12,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4759, 'grad_norm': 22.289886474609375, 'learning_rate': 8.000000000000001e-06, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 20%|‚ñà‚ñà        | 100/500 [06:16<12:12,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0034369230270386, 'eval_model_preparation_time': 0.0021, 'eval_wer': 20.334928229665074, 'eval_runtime': 41.6905, 'eval_samples_per_second': 0.24, 'eval_steps_per_second': 0.24, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|‚ñà‚ñà‚ñè       | 110/500 [06:39<15:34,  2.40s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3211, 'grad_norm': 10.545021057128906, 'learning_rate': 7.800000000000002e-06, 'epoch': 1.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|‚ñà‚ñà‚ñç       | 120/500 [06:58<12:23,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3404, 'grad_norm': 2.3022875785827637, 'learning_rate': 7.600000000000001e-06, 'epoch': 1.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|‚ñà‚ñà‚ñå       | 130/500 [07:18<12:30,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5095, 'grad_norm': 31.851993560791016, 'learning_rate': 7.4e-06, 'epoch': 1.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|‚ñà‚ñà‚ñä       | 140/500 [07:39<12:27,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.325, 'grad_norm': 40.030155181884766, 'learning_rate': 7.2000000000000005e-06, 'epoch': 1.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|‚ñà‚ñà‚ñà       | 150/500 [07:58<11:28,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2625, 'grad_norm': 15.562559127807617, 'learning_rate': 7e-06, 'epoch': 1.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 30%|‚ñà‚ñà‚ñà       | 150/500 [08:40<11:28,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7682459354400635, 'eval_model_preparation_time': 0.0021, 'eval_wer': 29.665071770334926, 'eval_runtime': 42.0321, 'eval_samples_per_second': 0.238, 'eval_steps_per_second': 0.238, 'epoch': 1.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 160/500 [09:02<13:51,  2.44s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4109, 'grad_norm': 22.275894165039062, 'learning_rate': 6.800000000000001e-06, 'epoch': 1.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|‚ñà‚ñà‚ñà‚ñç      | 170/500 [09:22<10:43,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2349, 'grad_norm': 0.8400312066078186, 'learning_rate': 6.600000000000001e-06, 'epoch': 1.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 180/500 [09:44<12:05,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.241, 'grad_norm': 10.485590934753418, 'learning_rate': 6.4000000000000006e-06, 'epoch': 1.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 190/500 [10:04<10:12,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.348, 'grad_norm': 27.068260192871094, 'learning_rate': 6.200000000000001e-06, 'epoch': 1.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 200/500 [10:24<09:45,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.445, 'grad_norm': 24.17538070678711, 'learning_rate': 6e-06, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 200/500 [11:09<09:45,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.174776077270508, 'eval_model_preparation_time': 0.0021, 'eval_wer': 22.966507177033492, 'eval_runtime': 44.7995, 'eval_samples_per_second': 0.223, 'eval_steps_per_second': 0.223, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 210/500 [11:31<11:49,  2.45s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0657, 'grad_norm': 6.5790934562683105, 'learning_rate': 5.8e-06, 'epoch': 2.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 220/500 [11:51<09:19,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0773, 'grad_norm': 0.44223669171333313, 'learning_rate': 5.600000000000001e-06, 'epoch': 2.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 230/500 [12:10<08:32,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2983, 'grad_norm': 0.8483469486236572, 'learning_rate': 5.400000000000001e-06, 'epoch': 2.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 240/500 [12:29<08:52,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0233, 'grad_norm': 46334.86328125, 'learning_rate': 5.2e-06, 'epoch': 2.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 250/500 [12:49<08:01,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1694, 'grad_norm': 9.999964714050293, 'learning_rate': 5e-06, 'epoch': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 250/500 [13:33<08:01,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.016852378845215, 'eval_model_preparation_time': 0.0021, 'eval_wer': 21.052631578947366, 'eval_runtime': 44.1138, 'eval_samples_per_second': 0.227, 'eval_steps_per_second': 0.227, 'epoch': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 260/500 [13:56<09:47,  2.45s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2375, 'grad_norm': 8.579090118408203, 'learning_rate': 4.800000000000001e-06, 'epoch': 2.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 270/500 [14:16<08:27,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1316, 'grad_norm': 7.611600399017334, 'learning_rate': 4.600000000000001e-06, 'epoch': 2.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 280/500 [14:37<07:49,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1842, 'grad_norm': 788.6686401367188, 'learning_rate': 4.4e-06, 'epoch': 2.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 290/500 [14:57<06:45,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2109, 'grad_norm': 17.46062660217285, 'learning_rate': 4.2000000000000004e-06, 'epoch': 2.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 300/500 [15:16<06:20,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.163, 'grad_norm': 6.95199728012085, 'learning_rate': 4.000000000000001e-06, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 300/500 [16:03<06:20,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3238627910614014, 'eval_model_preparation_time': 0.0021, 'eval_wer': 21.770334928229666, 'eval_runtime': 46.8709, 'eval_samples_per_second': 0.213, 'eval_steps_per_second': 0.213, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 310/500 [16:25<08:04,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1081, 'grad_norm': 0.1504455953836441, 'learning_rate': 3.8000000000000005e-06, 'epoch': 3.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 320/500 [16:45<05:52,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0377, 'grad_norm': 0.9341617822647095, 'learning_rate': 3.6000000000000003e-06, 'epoch': 3.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 330/500 [17:04<05:34,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0928, 'grad_norm': 1.579594373703003, 'learning_rate': 3.4000000000000005e-06, 'epoch': 3.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 340/500 [17:24<05:12,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.075, 'grad_norm': 0.15989607572555542, 'learning_rate': 3.2000000000000003e-06, 'epoch': 3.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 350/500 [17:45<05:03,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1373, 'grad_norm': 13.931048393249512, 'learning_rate': 3e-06, 'epoch': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 350/500 [18:31<05:03,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.0864601135253906, 'eval_model_preparation_time': 0.0021, 'eval_wer': 20.334928229665074, 'eval_runtime': 46.1942, 'eval_samples_per_second': 0.216, 'eval_steps_per_second': 0.216, 'epoch': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 360/500 [18:53<05:48,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0715, 'grad_norm': 14.488494873046875, 'learning_rate': 2.8000000000000003e-06, 'epoch': 3.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 370/500 [19:13<04:24,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1638, 'grad_norm': 25.46511459350586, 'learning_rate': 2.6e-06, 'epoch': 3.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 380/500 [19:33<03:54,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0229, 'grad_norm': 0.2048971951007843, 'learning_rate': 2.4000000000000003e-06, 'epoch': 3.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 390/500 [19:53<03:35,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0082, 'grad_norm': 0.14603818953037262, 'learning_rate': 2.2e-06, 'epoch': 3.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 400/500 [20:12<03:12,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0356, 'grad_norm': 0.15631593763828278, 'learning_rate': 2.0000000000000003e-06, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 400/500 [20:58<03:12,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.2087931632995605, 'eval_model_preparation_time': 0.0021, 'eval_wer': 22.248803827751196, 'eval_runtime': 46.0723, 'eval_samples_per_second': 0.217, 'eval_steps_per_second': 0.217, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 410/500 [21:21<04:05,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0517, 'grad_norm': 47682.56640625, 'learning_rate': 1.8000000000000001e-06, 'epoch': 4.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 420/500 [21:43<02:48,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0764, 'grad_norm': 27.824642181396484, 'learning_rate': 1.6000000000000001e-06, 'epoch': 4.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 430/500 [22:03<02:25,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0984, 'grad_norm': 8.994108200073242, 'learning_rate': 1.4000000000000001e-06, 'epoch': 4.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 440/500 [22:24<02:04,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0365, 'grad_norm': 13.948938369750977, 'learning_rate': 1.2000000000000002e-06, 'epoch': 4.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 450/500 [22:45<01:42,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0169, 'grad_norm': 0.666638195514679, 'learning_rate': 1.0000000000000002e-06, 'epoch': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 450/500 [23:28<01:42,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.09759521484375, 'eval_model_preparation_time': 0.0021, 'eval_wer': 29.665071770334926, 'eval_runtime': 43.4703, 'eval_samples_per_second': 0.23, 'eval_steps_per_second': 0.23, 'epoch': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 460/500 [23:51<01:42,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0301, 'grad_norm': 0.14688733220100403, 'learning_rate': 8.000000000000001e-07, 'epoch': 4.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 470/500 [24:13<01:03,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0288, 'grad_norm': 0.8899487853050232, 'learning_rate': 6.000000000000001e-07, 'epoch': 4.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 480/500 [24:35<00:42,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0202, 'grad_norm': 3.313755989074707, 'learning_rate': 4.0000000000000003e-07, 'epoch': 4.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 490/500 [24:57<00:21,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.058, 'grad_norm': 0.11994609981775284, 'learning_rate': 2.0000000000000002e-07, 'epoch': 4.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [25:18<00:00,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0282, 'grad_norm': 0.14573487639427185, 'learning_rate': 0.0, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [26:10<00:00,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.9231200218200684, 'eval_model_preparation_time': 0.0021, 'eval_wer': 22.248803827751196, 'eval_runtime': 51.6624, 'eval_samples_per_second': 0.194, 'eval_steps_per_second': 0.194, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['proj_out.weight'].\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [26:17<00:00,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1577.0689, 'train_samples_per_second': 0.317, 'train_steps_per_second': 0.317, 'train_loss': 0.37375612457096574, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=500, training_loss=0.37375612457096574, metrics={'train_runtime': 1577.0689, 'train_samples_per_second': 0.317, 'train_steps_per_second': 0.317, 'total_flos': 1.4429270016e+17, 'train_loss': 0.37375612457096574, 'epoch': 5.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1c80317fa3b1799d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1c80317fa3b1799d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(26567) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /Users/oussamanaji/Library/CloudStorage/OneDrive-CentraleSupelec/Diago_TOUT/WhisperHF/runs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
