{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from transformers import WhisperFeatureExtractor, WhisperTokenizer, WhisperProcessor\n",
    "from datasets import load_dataset\n",
    "import soundfile as sf\n",
    "from IPython.display import Audio\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from dask import delayed\n",
    "from datasets import load_from_disk\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aws_access_key_id=\"ASIA4PPDI6ALBMFZ7QEW\"\n",
    "# aws_secret_access_key=\"MxwKUrMU5wiyIMS2WfdEmN+K2jz9gOeUlJGBOCf7\"\n",
    "# aws_session_token=\"IQoJb3JpZ2luX2VjEAYaCWV1LXdlc3QtMyJHMEUCIAmkFWTZDG8ZziDIqx/3jrxvy6YBez8Ln9pCa7b+mQLpAiEAo9leNjgIoOP0Ped/O8+rby/Y47bdhfPAcuRqCaXbE6Uq9gIIXxAAGgw4NTc4NTk0ODU3MTgiDAfgSRDN4STMsCBucCrTAocIFVAw0YF8cwXDF34c61nBtXTexi9/D/Tm6AZcOZg+JiyTUm72kNyx1zUV38t2RC6WgX3hAm/j6Ce9BCmvwPe/uQrqznbUd4bVZfWc/OR6cTK7BePe0hb+hfrIbMJzhjODbqaAXDwk9E/waejcJukuV7XbZ1bZok6fQGpPc/wLrkXA4ookADrl1wB93O6INojIoFQDLN2s694/zX/j+9zPCyM/ycL+tnIhXGiUjoxOD3l47yYF4J1dqTVFO7N2dCGctXncRt9ojbElKwL8T1i8XhMlfMnItCDneK4fzVULj8Ldl88dB4+Wd2XdDYbsrbV1YI6nQ89X8/CXLsK5Ff+zLs3ctWNYteu5i0wUTdv10AEK1Wsc1RBkV9K7mi5NNyftKsazcQLJeYxns7pVHyKSKA0DV7JobdcqCgDGJUfuI9Yj1nE7seXOuhUt2MO+Tmby/DDgl5q4BjqnATu1Eikl/+wdO/JaxI1jKM77+UQrV4KGlvBZKNh7voSkezjFUIF3eJmmDpFF22TGAeRCQcVSwTSZoooJkUKJIkikIeF9CmrF679LrjoS+HqIU4+iay/Nr9eeZUGRDNXLaTHmSkMjh7Ge+7L8Mv3JmLvRkP1RQ2WRAJIsIJHQWdxmd/0hASKB538WR9vYKycfTOjjAjYFnZOVATmtj1+MP8z1ogB8EjrF\"\n",
    "\n",
    "# import boto3\n",
    "\n",
    "# s3 = boto3.client('s3', aws_access_key_id=aws_access_key_id, aws_secret_access_key=aws_secret_access_key, aws_session_token=aws_session_token)\n",
    "# s3_bucket = 'sagemaker-eu-west-3-857859485718'\n",
    "# response = s3.list_objects(Bucket=s3_bucket)\n",
    "# response\n",
    "\n",
    "# import s3fs\n",
    "# train_path = f's3://{s3_bucket}/oussama/train/'\n",
    "# test_path = f's3://{s3_bucket}/oussama/test/'\n",
    "# s3 = s3fs.S3FileSystem(key=aws_access_key_id, secret=aws_secret_access_key)\n",
    "# Charger les datasets depuis S3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"/Users/oussamanaji/Library/CloudStorage/OneDrive-CentraleSupelec/Diago_TOUT/WhisperHF/Dataset\"\n",
    "train_dataset = load_from_disk(f\"{dataset_dir}/train\")\n",
    "test_dataset = load_from_disk(f\"{dataset_dir}/test\")\n",
    "common_voice = DatasetDict()\n",
    "common_voice[\"train\"] = train_dataset\n",
    "common_voice[\"test\"] = test_dataset\n",
    "\n",
    "COLUMNS_TO_KEEP = [\"transcript\", \"audio\"]\n",
    "all_columns = common_voice[\"train\"].column_names\n",
    "columns_to_remove = set(all_columns) - set(COLUMNS_TO_KEEP)\n",
    "common_voice = common_voice.remove_columns(columns_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['audio', 'transcript'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['audio', 'transcript'],\n",
       "        num_rows: 10\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_voice[\"train\"] = common_voice[\"train\"].select(range(100))\n",
    "common_voice['test'] = common_voice[\"test\"].select(range(10))\n",
    "common_voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"openai/whisper-small\"\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(model_id)\n",
    "tokenizer = WhisperTokenizer.from_pretrained(model_id, language=\"French\", task=\"transcribe\")\n",
    "processor = WhisperProcessor.from_pretrained(model_id, language=\"French\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 100/100 [00:04<00:00, 22.32 examples/s]\n",
      "Map: 100%|██████████| 10/10 [00:00<00:00, 25.13 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def prepare_dataset(batch):\n",
    "    # load and resample audio data from 48 to 16kHz\n",
    "    audio = batch[\"audio\"]\n",
    "\n",
    "    # compute log-Mel input features from input audio array\n",
    "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "\n",
    "    # encode target text to label ids\n",
    "    batch[\"labels\"] = tokenizer(batch[\"transcript\"]).input_ids\n",
    "    return batch\n",
    "common_voice = common_voice.map(prepare_dataset, remove_columns=common_voice.column_names[\"train\"], num_proc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperForConditionalGeneration\n",
    "model = WhisperForConditionalGeneration.from_pretrained(model_id)\n",
    "model.generation_config.language = \"French\"\n",
    "model.generation_config.task = \"transcribe\"\n",
    "model.generation_config.forced_decoder_ids = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "import evaluate\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "    decoder_start_token_id: int\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
    "        # first treat the audio inputs by simply returning torch tensors\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # get the tokenized label sequences\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # pad the labels to max length\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        # if bos token is appended in previous tokenization step,\n",
    "        # cut bos token here as it's append later anyways\n",
    "        if (labels[:, 0] == self.decoder_start_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(\n",
    "    processor=processor,\n",
    "    decoder_start_token_id=model.config.decoder_start_token_id,\n",
    ")\n",
    "\n",
    "\n",
    "metric = evaluate.load(\"wer\")\n",
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    # replace -100 with the pad_token_id\n",
    "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "output_dir = \"/Users/oussamanaji/Library/CloudStorage/OneDrive-CentraleSupelec/Diago_TOUT/WhisperHF\"\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=output_dir,  # change to a repo name of your choice\n",
    "    per_device_train_batch_size=1,  # ou 2 si nécessaire\n",
    "    per_device_eval_batch_size=1,  # ou 2 si nécessaire\n",
    "    gradient_accumulation_steps=1,  # increase by 2x for every 2x decrease in batch size\n",
    "    learning_rate=1e-5,\n",
    "    #warmup_steps=500,\n",
    "    max_steps=500,\n",
    "    gradient_checkpointing=False,\n",
    "    fp16=False,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=128,\n",
    "    save_steps=50,\n",
    "    eval_steps=50,\n",
    "    logging_steps=10,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=common_voice[\"train\"],\n",
    "    eval_dataset=common_voice[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have passed task=transcribe, but also have set `forced_decoder_ids` to [[1, 50259], [2, 50359], [3, 50363]] which creates a conflict. `forced_decoder_ids` will be ignored in favor of task=transcribe.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "100%|██████████| 10/10 [00:38<00:00,  3.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription réelle: pendant le second siècle je fis serment d'ouvrir tous les trésors de la terre à quiconque me mettrait en liberté mais je ne fus pas plus heureux dans le troisième je promis de faire puissant monarque mon libérateur d'être toujours près de lui en esprit\n",
      "Transcription modèle :  Pendant le second siècle, je fis serment d'ouvrir tous les trésors de la terre, à qui compte-me mettre en liberté. Mais je ne fus pas plus heureux. Dans le troisième, je promis de faire puissant mon arc, mon libérateur, d'être toujours près de lui en esprit.\n",
      "--------------------------------------------------\n",
      "Transcription réelle: non ta mort est certaine dit le génie choisis seulement de quelle sorte tu veux que je te fasse mourir le pêcheur le voyant dans la résolution de le tuer en eut une douleur extrême non pas tant pour l'amour de lui qu'à cause de ses trois enfants dont il plaignait la misère où ils allaient être réduits par sa mort\n",
      "Transcription modèle :  — Non, ta mort est certaine, dit le génie. Choisis seulement de quelle sorte tu veux que je te fasse mourir. Le pêcheur, le voyant dans les résolutions de le tuer, enut une douleur extrême, non pas tant pour l'amour de lui qu'à cause de ces trois enfants dont il clénait la misère où ils allaient être réduits par sa mort.\n",
      "--------------------------------------------------\n",
      "Transcription réelle: la nuit suivante appela sa soeur quand il en fut temps si vous ne dormez pas ma soeur lui dit-elle je vous prie en attendant le jour qui paraîtra bientôt de continuer le conte du pêcheur\n",
      "Transcription modèle :  Dénarza, de la nuit suivante, a place à sœur quand il en fut temps. « Si vous ne dormez pas à ma sœur, lui dit-elle, je vous prie, en attendant le jour qui paraîtra bientôt, de continuer le compte du pêcheur. »\n",
      "--------------------------------------------------\n",
      "Transcription réelle: à l'aspect d'un monstre d'une grandeur si démesurée le pêcheur voulut prendre la fuite mais il se trouva si troublé et si effrayé qu'il ne put marcher salomon\n",
      "Transcription modèle :  À l'aspect d'un monstre d'une grandeur si démesurée, le pêcheur voulu prendre la suite, mais il se trouva si troublé et si effrayé qu'il ne pu marcher. « Salomon !\n",
      "--------------------------------------------------\n",
      "Transcription réelle: le sultan qui n'avait pas moins d'envie que dinarzade d'entendre la fin de ce conte différa encore la mort de la sultane fin de la dixième nuit cet enregistrement fait partie du domaine public\n",
      "Transcription modèle :  Le sultan qui n'avait pas moins d'envie que Dinarzad n'entend de la fin de ce compte diffère à encore la mort de la sultan. Fin de la dixième nuit. Cet enregistrement fait partie du domaine public.\n",
      "--------------------------------------------------\n",
      "Transcription réelle: s'écria d'abord le génie salomon grand prophète de dieu pardon pardon jamais je ne m'opposerai à vos volontés j'obéirai à tous vos commandements scheherazade apercevant le jour interrompit là son conte\n",
      "Transcription modèle :  S'écria d'abord le génie, Salomon, grand prophète de Dieu, pardon, pardon, jamais je ne me poserai vos volontés. Je baillerai à tous vos commandements. Chez Erasadz, apercevant le jour, interrompila son compte.\n",
      "--------------------------------------------------\n",
      "Transcription réelle: seigneur vous savez que je ne jette mes filets que quatre fois chaque jour je les ai déjà jetés trois fois sans avoir tiré le moindre fruit de mon travail il ne m'en reste plus qu'une je vous supplie de me rendre la mer favorable comme vous l'avez rendue à moïse\n",
      "Transcription modèle :  Seigneur, vous savez que je ne jette mes filets que quatre fois chaque jour. J'ai déjà jeté trois fois sans avoir tiré le moindre fruit de mon travail. Il ne m'en reste plus qu'une. Je vous supplie de me rendre le maire favorable, comme vous l'avez rendu à Moïse.\n",
      "--------------------------------------------------\n",
      "Transcription réelle: rien n'est plus surprenant que l'histoire du pêcheur répondit la sultane et vous en conviendrez la nuit prochaine si le sultan me fait la grâce de me laisser vivre schahriar curieux d'apprendre le succès de la pêche du pêcheur ne voulut pas faire mourir ce jour-là scheherazade\n",
      "Transcription modèle :  Rien n'est plus surprenant que l'histoire du pêcheur répondit la sultan, et vous en conviendrez la nuit prochaine si le sultan me fait la grâce de me laisser vivre. Chariar, curieux d'apprendre le succès de la pêche du pêcheur, ne voulu pas faire mourir ce jour-là chez Razad.\n",
      "--------------------------------------------------\n",
      "Transcription réelle: à ce discours le génie regardant le pêcheur d'un air fier lui répondit parle-moi plus civilement tu es bien hardi de m'appeler esprit superbe eh bien repartit le pêcheur vous parlerai-je avec plus de civilité en vous appelant hibou du bonheur\n",
      "Transcription modèle :  À ce discours, le génie, regardant le pêcheur de nerfière, lui répondit, « Parle-moi plus sililement, tu es bien hardi de m'appeler « Esprit Superbe ». « Et bien, repartis le pêcheur, vous parlerez-je avec plus de civilité en vous appelant « Ibu du bonheur » ? »\n",
      "--------------------------------------------------\n",
      "Transcription réelle: lui fit penser qu'il devait être rempli de quelque chose de précieux pour s'en éclaircir il prit son couteau et avec un peu de peine il l'ouvrit il en pencha aussitôt l'ouverture contre terre mais il n'en sortit rien ce qui le surprit extrêmement\n",
      "Transcription modèle :  lui fit penser qu'il devait être rempli de quelque chose de précieux. Pour s'en éclaircir, il prit son couteau, et avec un peu de peine, il l'ouvrit. Il en pencha aussitôt l'ouverture contre terre, mais il n'en sortit rien, ce qui le surprit extrêmement.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Faire des prédictions sur l'ensemble de test\n",
    "predictions = trainer.predict(common_voice[\"test\"])\n",
    "\n",
    "# Les ids des prédictions et des étiquettes\n",
    "pred_ids = predictions.predictions\n",
    "label_ids = predictions.label_ids\n",
    "\n",
    "# label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
    "\n",
    "# Décoder les prédictions et les étiquettes\n",
    "pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "label_str = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "for i in range(10):  # Par exemple, afficher les 10 premières\n",
    "    print(f\"Transcription réelle: {label_str[i]}\")\n",
    "    print(f\"Transcription modèle : {pred_str[i]}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 10/500 [00:18<16:36,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7014, 'grad_norm': 66834.4921875, 'learning_rate': 9.800000000000001e-06, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 20/500 [00:50<27:23,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.6648, 'grad_norm': 486.5415344238281, 'learning_rate': 9.600000000000001e-06, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 30/500 [01:21<23:33,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4579, 'grad_norm': 505.19488525390625, 'learning_rate': 9.4e-06, 'epoch': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 40/500 [01:49<19:20,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6163, 'grad_norm': 25.44746971130371, 'learning_rate': 9.200000000000002e-06, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 50/500 [02:12<16:37,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0226, 'grad_norm': 27.586471557617188, 'learning_rate': 9e-06, 'epoch': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 10%|█         | 50/500 [03:12<16:37,  2.22s/it]/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/modeling_utils.py:2618: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6243526935577393, 'eval_model_preparation_time': 0.0021, 'eval_wer': 49.52153110047847, 'eval_runtime': 60.2274, 'eval_samples_per_second': 0.166, 'eval_steps_per_second': 0.166, 'epoch': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 60/500 [04:14<49:32,  6.76s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4428, 'grad_norm': 31.742855072021484, 'learning_rate': 8.8e-06, 'epoch': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 70/500 [04:37<16:46,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5696, 'grad_norm': 12.226349830627441, 'learning_rate': 8.6e-06, 'epoch': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 80/500 [04:57<13:44,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7865, 'grad_norm': 27.385589599609375, 'learning_rate': 8.400000000000001e-06, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 90/500 [05:16<12:25,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7523, 'grad_norm': 15.013405799865723, 'learning_rate': 8.2e-06, 'epoch': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 100/500 [05:34<12:12,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4759, 'grad_norm': 22.289886474609375, 'learning_rate': 8.000000000000001e-06, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 20%|██        | 100/500 [06:16<12:12,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0034369230270386, 'eval_model_preparation_time': 0.0021, 'eval_wer': 20.334928229665074, 'eval_runtime': 41.6905, 'eval_samples_per_second': 0.24, 'eval_steps_per_second': 0.24, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 110/500 [06:39<15:34,  2.40s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3211, 'grad_norm': 10.545021057128906, 'learning_rate': 7.800000000000002e-06, 'epoch': 1.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 120/500 [06:58<12:23,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3404, 'grad_norm': 2.3022875785827637, 'learning_rate': 7.600000000000001e-06, 'epoch': 1.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 130/500 [07:18<12:30,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5095, 'grad_norm': 31.851993560791016, 'learning_rate': 7.4e-06, 'epoch': 1.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 140/500 [07:39<12:27,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.325, 'grad_norm': 40.030155181884766, 'learning_rate': 7.2000000000000005e-06, 'epoch': 1.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 150/500 [07:58<11:28,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2625, 'grad_norm': 15.562559127807617, 'learning_rate': 7e-06, 'epoch': 1.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 30%|███       | 150/500 [08:40<11:28,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7682459354400635, 'eval_model_preparation_time': 0.0021, 'eval_wer': 29.665071770334926, 'eval_runtime': 42.0321, 'eval_samples_per_second': 0.238, 'eval_steps_per_second': 0.238, 'epoch': 1.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 160/500 [09:02<13:51,  2.44s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4109, 'grad_norm': 22.275894165039062, 'learning_rate': 6.800000000000001e-06, 'epoch': 1.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 170/500 [09:22<10:43,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2349, 'grad_norm': 0.8400312066078186, 'learning_rate': 6.600000000000001e-06, 'epoch': 1.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 180/500 [09:44<12:05,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.241, 'grad_norm': 10.485590934753418, 'learning_rate': 6.4000000000000006e-06, 'epoch': 1.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 190/500 [10:04<10:12,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.348, 'grad_norm': 27.068260192871094, 'learning_rate': 6.200000000000001e-06, 'epoch': 1.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 200/500 [10:24<09:45,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.445, 'grad_norm': 24.17538070678711, 'learning_rate': 6e-06, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 40%|████      | 200/500 [11:09<09:45,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.174776077270508, 'eval_model_preparation_time': 0.0021, 'eval_wer': 22.966507177033492, 'eval_runtime': 44.7995, 'eval_samples_per_second': 0.223, 'eval_steps_per_second': 0.223, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 210/500 [11:31<11:49,  2.45s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0657, 'grad_norm': 6.5790934562683105, 'learning_rate': 5.8e-06, 'epoch': 2.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 220/500 [11:51<09:19,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0773, 'grad_norm': 0.44223669171333313, 'learning_rate': 5.600000000000001e-06, 'epoch': 2.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 230/500 [12:10<08:32,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2983, 'grad_norm': 0.8483469486236572, 'learning_rate': 5.400000000000001e-06, 'epoch': 2.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 240/500 [12:29<08:52,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0233, 'grad_norm': 46334.86328125, 'learning_rate': 5.2e-06, 'epoch': 2.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 250/500 [12:49<08:01,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1694, 'grad_norm': 9.999964714050293, 'learning_rate': 5e-06, 'epoch': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 50%|█████     | 250/500 [13:33<08:01,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.016852378845215, 'eval_model_preparation_time': 0.0021, 'eval_wer': 21.052631578947366, 'eval_runtime': 44.1138, 'eval_samples_per_second': 0.227, 'eval_steps_per_second': 0.227, 'epoch': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 260/500 [13:56<09:47,  2.45s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2375, 'grad_norm': 8.579090118408203, 'learning_rate': 4.800000000000001e-06, 'epoch': 2.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 270/500 [14:16<08:27,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1316, 'grad_norm': 7.611600399017334, 'learning_rate': 4.600000000000001e-06, 'epoch': 2.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 280/500 [14:37<07:49,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1842, 'grad_norm': 788.6686401367188, 'learning_rate': 4.4e-06, 'epoch': 2.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 290/500 [14:57<06:45,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2109, 'grad_norm': 17.46062660217285, 'learning_rate': 4.2000000000000004e-06, 'epoch': 2.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 300/500 [15:16<06:20,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.163, 'grad_norm': 6.95199728012085, 'learning_rate': 4.000000000000001e-06, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 60%|██████    | 300/500 [16:03<06:20,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3238627910614014, 'eval_model_preparation_time': 0.0021, 'eval_wer': 21.770334928229666, 'eval_runtime': 46.8709, 'eval_samples_per_second': 0.213, 'eval_steps_per_second': 0.213, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 310/500 [16:25<08:04,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1081, 'grad_norm': 0.1504455953836441, 'learning_rate': 3.8000000000000005e-06, 'epoch': 3.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 320/500 [16:45<05:52,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0377, 'grad_norm': 0.9341617822647095, 'learning_rate': 3.6000000000000003e-06, 'epoch': 3.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 330/500 [17:04<05:34,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0928, 'grad_norm': 1.579594373703003, 'learning_rate': 3.4000000000000005e-06, 'epoch': 3.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 340/500 [17:24<05:12,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.075, 'grad_norm': 0.15989607572555542, 'learning_rate': 3.2000000000000003e-06, 'epoch': 3.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 350/500 [17:45<05:03,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1373, 'grad_norm': 13.931048393249512, 'learning_rate': 3e-06, 'epoch': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 70%|███████   | 350/500 [18:31<05:03,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.0864601135253906, 'eval_model_preparation_time': 0.0021, 'eval_wer': 20.334928229665074, 'eval_runtime': 46.1942, 'eval_samples_per_second': 0.216, 'eval_steps_per_second': 0.216, 'epoch': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 360/500 [18:53<05:48,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0715, 'grad_norm': 14.488494873046875, 'learning_rate': 2.8000000000000003e-06, 'epoch': 3.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 370/500 [19:13<04:24,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1638, 'grad_norm': 25.46511459350586, 'learning_rate': 2.6e-06, 'epoch': 3.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 380/500 [19:33<03:54,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0229, 'grad_norm': 0.2048971951007843, 'learning_rate': 2.4000000000000003e-06, 'epoch': 3.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 390/500 [19:53<03:35,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0082, 'grad_norm': 0.14603818953037262, 'learning_rate': 2.2e-06, 'epoch': 3.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 400/500 [20:12<03:12,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0356, 'grad_norm': 0.15631593763828278, 'learning_rate': 2.0000000000000003e-06, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 80%|████████  | 400/500 [20:58<03:12,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.2087931632995605, 'eval_model_preparation_time': 0.0021, 'eval_wer': 22.248803827751196, 'eval_runtime': 46.0723, 'eval_samples_per_second': 0.217, 'eval_steps_per_second': 0.217, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 410/500 [21:21<04:05,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0517, 'grad_norm': 47682.56640625, 'learning_rate': 1.8000000000000001e-06, 'epoch': 4.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 420/500 [21:43<02:48,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0764, 'grad_norm': 27.824642181396484, 'learning_rate': 1.6000000000000001e-06, 'epoch': 4.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 430/500 [22:03<02:25,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0984, 'grad_norm': 8.994108200073242, 'learning_rate': 1.4000000000000001e-06, 'epoch': 4.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 440/500 [22:24<02:04,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0365, 'grad_norm': 13.948938369750977, 'learning_rate': 1.2000000000000002e-06, 'epoch': 4.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 450/500 [22:45<01:42,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0169, 'grad_norm': 0.666638195514679, 'learning_rate': 1.0000000000000002e-06, 'epoch': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 90%|█████████ | 450/500 [23:28<01:42,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.09759521484375, 'eval_model_preparation_time': 0.0021, 'eval_wer': 29.665071770334926, 'eval_runtime': 43.4703, 'eval_samples_per_second': 0.23, 'eval_steps_per_second': 0.23, 'epoch': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 460/500 [23:51<01:42,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0301, 'grad_norm': 0.14688733220100403, 'learning_rate': 8.000000000000001e-07, 'epoch': 4.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 470/500 [24:13<01:03,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0288, 'grad_norm': 0.8899487853050232, 'learning_rate': 6.000000000000001e-07, 'epoch': 4.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 480/500 [24:35<00:42,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0202, 'grad_norm': 3.313755989074707, 'learning_rate': 4.0000000000000003e-07, 'epoch': 4.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 490/500 [24:57<00:21,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.058, 'grad_norm': 0.11994609981775284, 'learning_rate': 2.0000000000000002e-07, 'epoch': 4.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [25:18<00:00,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0282, 'grad_norm': 0.14573487639427185, 'learning_rate': 0.0, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      "100%|██████████| 500/500 [26:10<00:00,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.9231200218200684, 'eval_model_preparation_time': 0.0021, 'eval_wer': 22.248803827751196, 'eval_runtime': 51.6624, 'eval_samples_per_second': 0.194, 'eval_steps_per_second': 0.194, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['proj_out.weight'].\n",
      "100%|██████████| 500/500 [26:17<00:00,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1577.0689, 'train_samples_per_second': 0.317, 'train_steps_per_second': 0.317, 'train_loss': 0.37375612457096574, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=500, training_loss=0.37375612457096574, metrics={'train_runtime': 1577.0689, 'train_samples_per_second': 0.317, 'train_steps_per_second': 0.317, 'total_flos': 1.4429270016e+17, 'train_loss': 0.37375612457096574, 'epoch': 5.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1c80317fa3b1799d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1c80317fa3b1799d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(26567) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /Users/oussamanaji/Library/CloudStorage/OneDrive-CentraleSupelec/Diago_TOUT/WhisperHF/runs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
